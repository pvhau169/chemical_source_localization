{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from policy.PytorchTraining import PytorchRunner\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import numpy as np\n",
    "from simulation.odorSimulation.aquaEnv import AquaEnv\n",
    "# from simulation.odorSimulation.aquaEnvGif import AquaEnv2DCropPaste as AquaEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 120\n"
     ]
    }
   ],
   "source": [
    "env_arg = {\n",
    "    # env_arg\n",
    "    \"mode\": 1,\n",
    "    \"boundary\": np.array([(-100, 100), (-100, 100)]),  # boundary of environment\n",
    "    \"boundary_map\": np.array([30, 20]),\n",
    "    \"time_step\": 200,  # simulation time_length\n",
    "    \"total_map_x\": 10,  # Heatmap resolution (10 x20)\n",
    "    \"total_map_y\": 4,\n",
    "    \"map_x\": 1,\n",
    "    \"map_y\": 1,\n",
    "\n",
    "    # water_flow\n",
    "    \"max_water_flow_force\": 7,  # water_flow_force vector\n",
    "    \"min_water_flow_force\": 3,  # water_flow_force vector\n",
    "    \"water_flow_force_shape\":2,\n",
    "    \"water_flow_force_scale\":2,\n",
    "    \"max_random_turbulence\": 1,\n",
    "    \"random_water_flow\": True,  # random_water_flow_force\n",
    "\n",
    "    # training\n",
    "    \"episode_limit\": 120,\n",
    "    \"feature_dim\": 3,\n",
    "\n",
    "    # reward design\n",
    "    'success_reward': 300,\n",
    "    \n",
    "    \"global_boundary\": torch.tensor([[0, 300], [-100, 100]]),\n",
    "    # \"local_boundary\": torch.tensor([[-100, 100], [-100, 100]]),\n",
    "    \"local_boundary\": torch.tensor([[-100, 100], [-100, 100]]),\n",
    "    \n",
    "    \"global_map_boundary\": torch.tensor([[0, 30], [0, 20]]),\n",
    "    \"local_map_boundary\": torch.tensor([[0, 20], [0, 20]]),\n",
    "    \n",
    "    \"local_map_size\": (20, 20),\n",
    "    \"global_map_size\": (30, 20),\n",
    "    \n",
    "    \"directions\": torch.tensor([[0, -1], [0, 1]]),\n",
    "    \"dt\":5,\n",
    "}\n",
    "\n",
    "agent_arg = {\n",
    "    \"start_position\": np.array([0, 0]),\n",
    "    \"dt\": 8,\n",
    "    \"speed\": 1,\n",
    "    \"radius\": 10,\n",
    "\n",
    "    # possible actions\n",
    "    \"directions\": np.array([[1, 0], [0, 1], [-1, 0], [0, -1]]),   #np.array([[0, -1], [0, 1]]), # up/down action \n",
    "    \"action_dim\": 4,\n",
    "\n",
    "    # initialize\n",
    "    \"random_start\": False,\n",
    "    \"random_range\": np.array([[0.4, 1], [0, 1]]),\n",
    "    \"random_direction\": True,\n",
    "    \n",
    "    #action mode\n",
    "    'action_mode': 1, #2, #0: up_down, 1:cyclone\n",
    "    \n",
    "    #updown range\n",
    "    \"updown_range\" : np.array([0, 1]),\n",
    "\n",
    "}\n",
    "\n",
    "source_arg = {\n",
    "    \"position\": np.array([0, 0]),\n",
    "    \"source_pos_shape\": 8,\n",
    "    \"source_pos_scale\":12,\n",
    "    \"dt\": 1,\n",
    "    \"decay_rate\": 0.97,\n",
    "    \"spawn_scale\": 0.2,  # source produces \"concentration/spawn scale\" odor packets per time_step\n",
    "    \"size_scale\": 1.05,\n",
    "    \"concentration_threshold\": 0.3,\n",
    "    \n",
    "    # initialize\n",
    "    \"random_start\": True,\n",
    "    \"random_range\": np.array([[0, 1], [0.3, 0.7]]),\n",
    "    \"random_direction\": True,\n",
    "    \"random_concentration\": True,\n",
    "    \"min_concentration\": 0.6,\n",
    "    \"max_concentration\": 1.0,\n",
    "    \"burn_in\": True,\n",
    "}\n",
    "\n",
    "wind_arg = {\n",
    "    # Turbulence\n",
    "    \"energy\": 0.2,\n",
    "    \"length_scale\": 10,\n",
    "    \"tau_f\": 5,\n",
    "    \"sampling_interval\": 1 / 2,\n",
    "}\n",
    "\n",
    "env_arg['action_dim'] = agent_arg['action_dim']\n",
    "env_arg['directions'] = torch.tensor(agent_arg['directions'])\n",
    "\n",
    "# generate environment\n",
    "\n",
    "env = AquaEnv(env_arg, agent_arg, source_arg, wind_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_example = 12000\n",
    "save_interval = 2000\n",
    "save_list = [\"boundary\", \n",
    "             \"source.concentration\",\n",
    "             \"source.position\",\n",
    "             \"wind.water_flow_force\",\n",
    "             \"agent.position\"\n",
    "             \n",
    "             \"detect_total_concentration\",\n",
    "             \"detect_avg_concentration\",\n",
    "             \"detect_water_flow_force\",\n",
    "             \"detect_source\",\n",
    "             ]\n",
    "\n",
    "save_list = [(\"self\", \"boundary\"), \n",
    "             (\"self.source\", \"concentration\"),\n",
    "             (\"self.source\", \"position\"),\n",
    "             (\"self.wind\", \"water_flow_force\"),\n",
    "             (\"self\", \"agent_position\"),\n",
    "             (\"self\", \"agent_start\"),\n",
    "             (\"self\", \"action\"),\n",
    "             \n",
    "             (\"self\", \"detect_total_concentration\"),\n",
    "             (\"self\", \"detect_water_flow_force\"),\n",
    "             (\"self\", \"detect_source\"),\n",
    "             \n",
    "             ]\n",
    "episode_data = env.getEpisodeData(save_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [9:29:07<00:00,  2.85s/it]  \n"
     ]
    }
   ],
   "source": [
    "# file = \"stochastic\"\n",
    "file = \"cyclone\"\n",
    "\n",
    "agent_arg['action_mode'] = 1\n",
    "# generate data\n",
    "from tqdm import tqdm\n",
    "from common.utils import Logger\n",
    "data_log = Logger()\n",
    "log_path = \"../output/data/\"+file+\"/data_{}.txt\"\n",
    "for i_example in tqdm(range(n_example)):\n",
    "    env.reset()\n",
    "    episode_data = env.getEpisodeData(save_list)\n",
    "    while np.sum(np.array(episode_data['detect_total_concentration'])>0)<5:\n",
    "        episode_data = env.getEpisodeData(save_list)    \n",
    "    data_log.addListItem(episode_data)\n",
    "    \n",
    "    if (i_example+1) % save_interval == 0 or i_example == 0:\n",
    "        data_log.writeToFile(log_path.format(round(i_example/save_interval)))\n",
    "        data_log = Logger()\n",
    "        \n",
    "# data_log.writeToFile(log_path.format(i_example//save_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [4:03:10<00:00,  1.46s/it] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_example = 10000\n",
    "save_interval = 2000\n",
    "# generate data\n",
    "from tqdm import tqdm\n",
    "from common.utils import Logger\n",
    "data_log = Logger()\n",
    "log_path = \"../output/data/\"+file+\"/data_{}.txt\"\n",
    "for i_example in tqdm(range(n_example)):\n",
    "    env.reset()\n",
    "    episode_data = env.getEpisodeData(save_list)\n",
    "    \n",
    "    data_log.addListItem(episode_data)\n",
    "    \n",
    "    if (i_example+1) % save_interval == 0 or i_example == 0:\n",
    "        data_log.writeToFile(log_path.format(round(i_example/save_interval)))\n",
    "        data_log = Logger()\n",
    "        \n",
    "# data_log.writeToFile(log_path.format(i_example//save_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12000/12000 [4:52:12<00:00,  1.46s/it]  \n"
     ]
    }
   ],
   "source": [
    "agent_arg['action_mode'] = 1\n",
    "# generate data\n",
    "from tqdm import tqdm\n",
    "from common.utils import Logger\n",
    "data_log = Logger()\n",
    "log_path = \"../output/data/cyclone/data_{}.txt\"\n",
    "for i_example in tqdm(range(n_example)):\n",
    "    env.reset()\n",
    "    episode_data = env.getEpisodeData(save_list)\n",
    "    # while np.sum(np.array(episode_data['detect_total_concentration'])>0)==0:\n",
    "    #     episode_data = env.getEpisodeData(save_list)    \n",
    "    data_log.addListItem(episode_data)\n",
    "    \n",
    "    if (i_example+1) % save_interval == 0 or i_example == 0:\n",
    "        data_log.writeToFile(log_path.format(round(i_example/save_interval)))\n",
    "        data_log = Logger()\n",
    "        \n",
    "data_log.writeToFile(log_path.format(i_example//save_interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.65308074, -1.88963978]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.wind.getTurbulenceVector([[100, 0]], 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7fe377ed49a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mepisode_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'action'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "def getSensingObservation(self):\n",
    "    def getMapPosition(positions):\n",
    "        interval_map = (np.sum(np.abs(self.boundary), axis=1) / self.boundary_map)[np.newaxis, ...]  # (1, 2)\n",
    "        map_positions = (positions - self.boundary[:, 0][np.newaxis, ...]) / interval_map\n",
    "        return map_positions.astype(np.int)\n",
    "\n",
    "    def updateEnvMap():\n",
    "        packets_position, packets_concentration = self.source.packets_position, self.source.packets_concentration\n",
    "        packets_map_position = getMapPosition(packets_position)\n",
    "\n",
    "        map_x, map_y = self.boundary_map\n",
    "        for i_x in range(map_x):\n",
    "            for i_y in range(map_y):\n",
    "                cell_position_mask = (packets_map_position[:, 0] == i_x) & (packets_map_position[:, 1] == i_y)\n",
    "                cell_total_concentration = np.sum(packets_concentration[cell_position_mask])\n",
    "                cell_n_packet = len(packets_concentration[cell_position_mask])\n",
    "                self.total_concentration_map[i_x, i_y][self.t_step] = cell_total_concentration\n",
    "                self.occurence_rate_map[i_x, i_y][self.t_step] = cell_n_packet\n",
    "\n",
    "    updateEnvMap()\n",
    "    agent_position = getMapPosition(self.agent.position)[0]  # (2)\n",
    "    total_concen = self.total_concentration_map[agent_position[0], agent_position[1]][:self.t_step+1]  # (1,time_len)\n",
    "    if len(total_concen) == 0:\n",
    "        total_concen = 0\n",
    "    total_concen = np.atleast_2d(np.mean(total_concen))\n",
    "    # print(total_concen, np.sum(self.total_concentration_map))\n",
    "\n",
    "    # observation = (total_concentration, water_flow_force)\n",
    "    agent_water_flow_force = self.wind.getTurbulenceVector(self.agent.position[np.newaxis, ...], self.t)  # (1,2)\n",
    "    obs = np.concatenate((total_concen, agent_water_flow_force), axis=-1)  # (1,3)\n",
    "\n",
    "    # generate data purpose\n",
    "    self.detect_total_concentration = total_concen\n",
    "    self.detect_water_flow_force = agent_water_flow_force\n",
    "\n",
    "    torch_obs = torch.from_numpy(obs).type(torch.float)\n",
    "\n",
    "    # generate data purpose\n",
    "    self.detect_total_concentration = total_concen\n",
    "    self.detect_water_flow_force = agent_water_flow_force\n",
    "    if total_concen > 0: self.detect_source = 1\n",
    "\n",
    "    self.source_concentration = self.source.concentration\n",
    "    return torch_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[155, 0],\n",
       " [155, 5],\n",
       " [155, 10],\n",
       " [150, 10],\n",
       " [145, 10],\n",
       " [145, 5],\n",
       " [145, 0],\n",
       " [145, -5],\n",
       " [150, -5],\n",
       " [155, -5],\n",
       " [160, -5],\n",
       " [160, 0],\n",
       " [160, 5],\n",
       " [160, 10],\n",
       " [160, 15],\n",
       " [155, 15],\n",
       " [150, 15],\n",
       " [145, 15],\n",
       " [140, 15],\n",
       " [140, 10],\n",
       " [140, 5],\n",
       " [140, 0],\n",
       " [140, -5],\n",
       " [140, -10],\n",
       " [145, -10],\n",
       " [150, -10],\n",
       " [155, -10],\n",
       " [160, -10],\n",
       " [165, -10],\n",
       " [165, -5],\n",
       " [165, 0],\n",
       " [165, 5],\n",
       " [165, 10],\n",
       " [165, 15],\n",
       " [165, 20],\n",
       " [160, 20],\n",
       " [155, 20],\n",
       " [150, 20],\n",
       " [145, 20],\n",
       " [140, 20],\n",
       " [135, 20],\n",
       " [135, 15],\n",
       " [135, 10],\n",
       " [135, 5],\n",
       " [135, 0],\n",
       " [135, -5],\n",
       " [135, -10],\n",
       " [135, -15],\n",
       " [140, -15],\n",
       " [145, -15],\n",
       " [150, -15],\n",
       " [155, -15],\n",
       " [160, -15],\n",
       " [165, -15],\n",
       " [170, -15],\n",
       " [170, -10],\n",
       " [170, -5],\n",
       " [170, 0],\n",
       " [170, 5],\n",
       " [170, 10],\n",
       " [170, 15],\n",
       " [170, 20],\n",
       " [170, 25],\n",
       " [165, 25],\n",
       " [160, 25],\n",
       " [155, 25],\n",
       " [150, 25],\n",
       " [145, 25],\n",
       " [140, 25],\n",
       " [135, 25],\n",
       " [130, 25],\n",
       " [130, 20],\n",
       " [130, 15],\n",
       " [130, 10],\n",
       " [130, 5],\n",
       " [130, 0],\n",
       " [130, -5],\n",
       " [130, -10],\n",
       " [130, -15],\n",
       " [130, -20]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_data['agent_position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "position = torch.tensor([0,0])\n",
    "directions = torch.tensor([[0, 1], [-1, 0], [0, -1], [1, 0]])\n",
    "action = 2\n",
    "scale = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, -0.5000])\n",
      "tensor([0., -0.]) tensor([ 0.0000, -0.5000])\n"
     ]
    }
   ],
   "source": [
    "position = position + directions[action] * scale\n",
    "print(position)\n",
    "map_action = position // 1\n",
    "position = position - position //1\n",
    "print(map_action, position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.position = self.position + self.directions[action.squeeze(1)] * self.scale\n",
    "        self.map_action = self.position // 1\n",
    "        self.position = self.position - self.position //1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([-1.5])\n",
    "a//1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f329f37f787433c1df56b29cd79e40088fe5f8fc73e5de248e5bf86c97ff8a6"
  },
  "kernelspec": {
   "display_name": "PyCharm (odorSimulation)",
   "language": "python",
   "name": "pycharm-789226fa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
